{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hheoo\n"
     ]
    }
   ],
   "source": [
    "from monai.utils import first, set_determinism\n",
    "import monai.transforms \n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.data import CacheDataset, DataLoader, Dataset\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "\n",
    "from monai.inferers import sliding_window_inference\n",
    "print(\"hheoo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = './datasets/Data_Train_Test'\n",
    "model_dir = './results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './results/loss_train.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mloss_train.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m train_metric \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetric_train.npy\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      3\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_test.npy\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './results/loss_train.npy'"
     ]
    }
   ],
   "source": [
    "train_loss = np.load(os.path.join(model_dir, 'loss_train.npy'))\n",
    "train_metric = np.load(os.path.join(model_dir, 'metric_train.npy'))\n",
    "test_loss = np.load(os.path.join(model_dir, 'loss_test.npy'))\n",
    "test_metric = np.load(os.path.join(model_dir, 'metric_test.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"Results 25 june\", (12, 6))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title(\"Train dice loss\")\n",
    "x = [i + 1 for i in range(len(train_loss))]\n",
    "y = train_loss\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title(\"Train metric DICE\")\n",
    "x = [i + 1 for i in range(len(train_metric))]\n",
    "y = train_metric\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.title(\"Test dice loss\")\n",
    "x = [i + 1 for i in range(len(test_loss))]\n",
    "y = test_loss\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.title(\"Test metric DICE\")\n",
    "x = [i + 1 for i in range(len(test_metric))]\n",
    "y = test_metric\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_volumes = sorted(glob(os.path.join(in_dir, \"TrainVolumes\", \"*.nii.gz\")))\n",
    "path_train_segmentation = sorted(glob(os.path.join(in_dir, \"TrainSegmentation\", \"*.nii.gz\")))\n",
    "\n",
    "path_test_volumes = sorted(glob(os.path.join(in_dir, \"TestVolumes\", \"*.nii.gz\")))\n",
    "path_test_segmentation = sorted(glob(os.path.join(in_dir, \"TestSegmentation\", \"*.nii.gz\")))\n",
    "\n",
    "train_files = [{\"vol\": image_name, \"seg\": label_name} for image_name, label_name in zip(path_train_volumes, path_train_segmentation)]\n",
    "test_files = [{\"vol\": image_name, \"seg\": label_name} for image_name, label_name in zip(path_test_volumes, path_test_segmentation)]\n",
    "test_files = test_files[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"vol\", \"seg\"]),\n",
    "        AddChanneld(keys=[\"vol\", \"seg\"]),\n",
    "        Spacingd(keys=[\"vol\", \"seg\"], pixdim=(1.5,1.5,1.0), mode=(\"bilinear\", \"nearest\")),\n",
    "        Orientationd(keys=[\"vol\", \"seg\"], axcodes=\"RAS\"),\n",
    "        ScaleIntensityRanged(keys=[\"vol\"], a_min=-200, a_max=200,b_min=0.0, b_max=1.0, clip=True), \n",
    "        CropForegroundd(keys=['vol', 'seg'], source_key='vol'),\n",
    "        Resized(keys=[\"vol\", \"seg\"], spatial_size=[128,128,64]),   \n",
    "        ToTensord(keys=[\"vol\", \"seg\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = Dataset(data=test_files, transform=test_transforms)\n",
    "test_loader = DataLoader(test_ds, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "model = UNet(\n",
    "    dimensions=3,\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    channels=(16, 32, 64, 128, 256), \n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    "    norm=Norm.BATCH,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\n",
    "    os.path.join(model_dir, \"best_metric_model.pth\")))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sw_batch_size = 4\n",
    "roi_size = (128, 128, 64)\n",
    "with torch.no_grad():\n",
    "    test_patient = first(test_loader)\n",
    "    t_volume = test_patient['vol']\n",
    "    #t_segmentation = test_patient['seg']\n",
    "    \n",
    "    test_outputs = sliding_window_inference(t_volume.to(device), roi_size, sw_batch_size, model)\n",
    "    sigmoid_activation = Activations(sigmoid=True)\n",
    "    test_outputs = sigmoid_activation(test_outputs)\n",
    "    test_outputs = test_outputs > 0.53\n",
    "        \n",
    "    for i in range(32):\n",
    "        # plot the slice [:, :, 80]\n",
    "        plt.figure(\"check\", (18, 6))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.title(f\"image {i}\")\n",
    "        plt.imshow(test_patient[\"vol\"][0, 0, :, :, i], cmap=\"gray\")\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.title(f\"label {i}\")\n",
    "        plt.imshow(test_patient[\"seg\"][0, 0, :, :, i] != 0)\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title(f\"output {i}\")\n",
    "        plt.imshow(test_outputs.detach().cpu()[0, 1, :, :, i])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: monai in /home/devdatta/.local/lib/python3.10/site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from monai) (1.26.3)\n",
      "Requirement already satisfied: torch>=1.9 in /home/devdatta/.local/lib/python3.10/site-packages (from monai) (2.2.1)\n",
      "Requirement already satisfied: filelock in /home/devdatta/.local/lib/python3.10/site-packages (from torch>=1.9->monai) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/devdatta/.local/lib/python3.10/site-packages (from torch>=1.9->monai) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/devdatta/.local/lib/python3.10/site-packages (from torch>=1.9->monai) (1.12)\n",
      "Requirement already satisfied: networkx in /home/devdatta/.local/lib/python3.10/site-packages (from torch>=1.9->monai) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/devdatta/.local/lib/python3.10/site-packages (from torch>=1.9->monai) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/devdatta/.local/lib/python3.10/site-packages (from torch>=1.9->monai) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/devdatta/.local/lib/python3.10/site-packages (from torch>=1.9->monai) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/devdatta/.local/lib/python3.10/site-packages (from torch>=1.9->monai) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/devdatta/.local/lib/python3.10/site-packages (from torch>=1.9->monai) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/devdatta/.local/lib/python3.10/site-packages (from torch>=1.9->monai) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/devdatta/.local/lib/python3.10/site-packages (from torch>=1.9->monai) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/devdatta/.local/lib/python3.10/site-packages (from torch>=1.9->monai) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/devdatta/.local/lib/python3.10/site-packages (from torch>=1.9->monai) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/devdatta/.local/lib/python3.10/site-packages (from torch>=1.9->monai) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/devdatta/.local/lib/python3.10/site-packages (from torch>=1.9->monai) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/devdatta/.local/lib/python3.10/site-packages (from torch>=1.9->monai) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/devdatta/.local/lib/python3.10/site-packages (from torch>=1.9->monai) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/devdatta/.local/lib/python3.10/site-packages (from torch>=1.9->monai) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/devdatta/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.9->monai) (12.4.99)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/devdatta/.local/lib/python3.10/site-packages (from jinja2->torch>=1.9->monai) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/devdatta/.local/lib/python3.10/site-packages (from sympy->torch>=1.9->monai) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install monai"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "af407973ba12897262deda9d8992946cc1a9873fff2de40f1acc89cdf9010052"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
